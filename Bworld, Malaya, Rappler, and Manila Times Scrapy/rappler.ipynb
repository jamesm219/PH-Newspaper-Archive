{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('rappler.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "df['date'] = df['date'].str.split(' ').str[:3].str.join(' ')\n",
    "\n",
    "df['date'] = df['date'].str.replace('June', 'Jun')\n",
    "\n",
    "df['date'] = df['date'].str.replace('July', 'Jul')\n",
    "\n",
    "df['date'] = df['date'].str.replace('April', 'Apr')\n",
    "\n",
    "df['date'] = df['date'].str.replace(',', '')\n",
    "\n",
    "def check_date_format(date_str, format='%b %d %Y'):\n",
    "    try:\n",
    "        datetime.strptime(date_str, format)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "current_time = datetime.now().strftime('%b %d %Y')\n",
    "df['date'] = df['date'].apply(lambda x: x if check_date_format(x) else current_time)\n",
    "\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'], format='%b %d %Y')\n",
    "\n",
    "df['date'] = df['date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "sentiment = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "sentiment_scores = []\n",
    "label = []\n",
    "\n",
    "for title in df['title']:\n",
    "    score = sentiment(title)\n",
    "    sentiment_scores.append(score[0]['score'])\n",
    "    label.append(score[0]['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_data = {\n",
    "    'score': sentiment_scores,\n",
    "    'label': label\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(transformers_data)\n",
    "\n",
    "df2['label'] = df2['label'].str.replace('LABEL_0', 'NEGATIVE')\n",
    "df2['label'] = df2['label'].str.replace('LABEL_1', 'NEUTRAL')\n",
    "df2['label'] = df2['label'].str.replace('LABEL_2', 'POSITIVE')\n",
    "\n",
    "df3 = pd.concat([df, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"****\",\n",
    "    database=\"ph_newspaper\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db_connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('mysql+mysqlconnector://root:****@localhost/ph_newspaper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.to_sql('philstar', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries have been deleted.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT title, MIN(article_id) AS min_article_id\n",
    "        FROM philstar\n",
    "        GROUP BY title\n",
    "        HAVING COUNT(*) > 1\n",
    "    \"\"\")\n",
    "    duplicate_titles = cursor.fetchall()\n",
    "\n",
    "    for title, min_article_id in duplicate_titles:\n",
    "        cursor.execute(\"\"\"\n",
    "            DELETE FROM philstar\n",
    "            WHERE title = %s AND article_id <> %s\n",
    "        \"\"\", (title, min_article_id))\n",
    "    \n",
    "    cursor.execute(\"\"\"UPDATE philstar\n",
    "    SET date = REPLACE(date, ' , / ', '')\"\"\")\n",
    "\n",
    "    cursor.execute(\"\"\"UPDATE philstar\n",
    "    SET date = TRIM(date)\"\"\")\n",
    "\n",
    "    cursor.execute(\"\"\"DELETE FROM philstar\n",
    "    WHERE article = 'Premium,Â© The Financial Times Limited 2024. All Rights Reserved.,Not to be redistributed, copied or modified in any way.,Digital edition access ,Ad-free access '\"\"\")\n",
    "\n",
    "    db_connection.commit()\n",
    "    print(\"Duplicate entries have been deleted.\")\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    db_connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
